---
title: "Predicting readmission probability for diabetes inpatients"
author: 
- Annie Vo
- Sarah Hayward
- Jessica Brown
date: ' '
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---

* to hide source code: echo = FALSE
* to hide text output: results = 'hide' or results = FALSE
* hide messages: message = FALSE
* hide warning messages: warning = FALSE
* hide plotsL fig.show = 'hide'

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 7, fig.height = 4)
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, glmnet, car, data.table, GGally, leaps, gglasso, ggpubr, gridExtra, pROC)   #add your packages here
```

# Executive Summary 

# Data Summary / EDA
* Nature of the data, origin
* Necessary quantitative and graphical summaries
* Are there any problems with the data?
* Which variables are considered as input 


```{r, echo=FALSE, results=FALSE}
diabetes <- read.csv("diabetic.data.csv")
#names(diabetes)
```


```{r, results = FALSE}
readmission <- read.csv("readmission.csv")
#head(readmission)
#summary(readmission)
#names(readmission)
```


```{r, results = FALSE}
readmission$race <- as.factor(readmission$race)
```
```{r,results = FALSE}
readmission$gender <- as.factor(readmission$gender)
```


The original data is from the [Center for Clinical and Translational Research](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008) at Virginia Commonwealth University. It covers data on diabetes patients across 130 U.S. hospitals from 1999 to 2008. There are over 100,000 unique hospital admissions in this dataset, from ~70,000 unique patients. The data includes demographic elements, such as age, gender, and race, as well as clinical attributes such as tests conducted, emergency/inpatient visits, etc.

For our analysis we will use a cleaned subset of this dataset which excludes variables with lots of missing values and variables with very little variability, as well as applying binning on some categorical variables. 

The event of interest is **readmitted within < 30 days**. 

```{r,results = FALSE}
#create response variable for readmit within <30 days
readmission$lessThanThirty <- ifelse(readmission$readmitted == "<30", 1, 0)
sum(readmission$lessThanThirty)
```
From our dataset that we are using to create out model we see that there are 11,357 patients that were readmitted in less than 30 days out of the full 101,766 patients that we have data for. 

```{r}
p1 <- ggplot(readmission, aes(x = factor(gender), fill = gender)) +
  geom_bar(stat = "count", width = 0.7, color = "black") + 
  scale_fill_brewer(palette="Greens") + 
  xlab("gender") +
  ggtitle("Distribution of Gender in Cleaned Dataset") + 
  theme_minimal()

p2<- ggplot(readmission, aes(x = factor(lessThanThirty), fill = gender)) +
  geom_bar(stat = "count", width = 0.7, position = position_dodge(), color = "black") + 
  scale_fill_brewer(palette="Greens") + 
  xlab("Readmitted Within <30 Days") +
  ggtitle("Distribution of Gender with Response Variable") +
  theme_minimal()
ggarrange(p1, p2, ncol = 2, nrow = 1)

```
Based on our data, we can see that there are slightly more females than males included in the study.

```{r}
p3 <- ggplot(readmission, aes(x = factor(race), fill = race)) +
  geom_bar(stat = "count", width = 0.7, color = "black") + 
  scale_fill_brewer(palette="Reds") + 
  xlab("race") +
  ggtitle("Distribution of Race in Cleaned Dataset") + 
  theme_minimal()

p4<- ggplot(readmission, aes(x = factor(lessThanThirty), fill = race)) +
  geom_bar(stat = "count", width = 0.7, color = "black") + 
  scale_fill_brewer(palette="Reds") + 
  xlab("Readmitted Within <30 Days") +
  ggtitle("Distribution of Race with Response Variable") +
  theme_minimal()

ggarrange(p3, p4, ncol = 2, nrow = 1)

```


```{r}
p5 <- ggplot(readmission, aes(x = factor(age_mod), fill = age_mod)) +
  geom_bar(stat = "count", width = 0.7, color = "black") + 
  scale_fill_brewer(palette="Blues") + 
  labs(title = "Distribution of Age in Cleaned Dataset", fill = "Age group", x = "Age group") + 
  theme_minimal()
p6 <- ggplot(readmission, aes(x = factor(age_mod), fill = gender)) +
  geom_bar(stat = "count", width = 0.7, color = "black", position = position_dodge()) + 
  scale_fill_brewer(palette="Greens") + 
  labs(title = "Distribution of Gender for Each Age Group", fill = "Gender", x = "Age group") + 
  theme_minimal()

ggarrange(p5, p6, ncol = 2, nrow = 1)
```

```{r}
ggplot(readmission, aes(x = num_medications)) +
  geom_boxplot(fill = "pink") + 
  labs(x = "Number of Medications", title = "Distribution of Number of Medications") + 
  theme_minimal()
```

Here we begin our variable selection. We start by removing certain variables that are not needed for the study such as patient identifiers and duplicate variables. Our next step is to clean the remaining data. Since we don't have access to additional records for the patients, we decided to remove the patients in which there was missing information, such as those whose race was coded as "?". Due to the large size of our data set, removing these data points should not have a great impact on the analysis and the final model.
```{r}
readmission_sub <- readmission %>% select(-encounter_id, -patient_nbr, -readmitted)
```

```{r, results=FALSE}
nrow(readmission_sub %>% filter((gender == "Unknown/Invalid") | (race == "?")))
```

```{r}
readmission_sub <- readmission_sub %>% filter((race != "?") & (gender != "Unknown/Invalid") & (diag3_mod != "?"))
readmission_sub <- droplevels(readmission_sub)
lapply(readmission_sub, unique)
```

```{r}
X <- model.matrix(lessThanThirty~., readmission_sub)[,-1]
dim(X)
```

```{r}
Y <- readmission_sub$lessThanThirty
```

```{r}
#takes a while to run
set.seed(10)
fit1.cv <- cv.glmnet(X, Y,  alpha=1, family="binomial", nfolds = 10, type.measure = "deviance")
plot(fit1.cv)
```

```{r}
coef.1se <- coef(fit1.cv, s="lambda.1se")
coef.1se <- coef.1se[which(coef.1se !=0),]
coef.1se
```

```{r, results = TRUE}
#might want to put these results into the appendix
rownames(as.matrix(coef.1se))
```
Here we are looking at the coefficients that LASSO selected for lamda.1se. Which is the value of lambda that gives the most regularized model such that the cross-validated error is within one standard error of the minimum. We have 12 different overall variables that were selected with some of them having multiple levels in this model, there are a total of 21 coefficients and the intercept. 


```{r, results=FALSE}
coef.min <- coef(fit1.cv, s="lambda.min")
coef.min <- coef.min[which(coef.min !=0), ]
as.matrix(coef.min)
```

```{r, results=TRUE}
#might want to put these results into the apendix
beta.min <- rownames(as.matrix(coef.min))
length(beta.min)
```
Here we are looking at the coefficients that LASSO selected for lamda.min. Which is the value of lamda that gives minimum mean cross-validated error. We can note that many more variables were selected in this model with additional levels for some of the factors that were included in the 1se model. We can see that 28 variables were selected for this model, which is every single variable that we are using in this model, however not all of the levels were included for each of the factor variables. 

Now we will start to fit glm to the variables that LASSO selected. We will start with the model for lamda min. Since we have factor variables in which not all of the levels were selected, we decided to force all of the levels in since there is not easy way to remove just one level. 

```{r}
model.1 <- glm(lessThanThirty~ race + time_in_hospital + num_lab_procedures + num_procedures + num_medications + number_outpatient + number_emergency + number_inpatient + number_diagnoses + max_glu_serum + A1Cresult + metformin + glimepiride + glipizide + glyburide + pioglitazone + rosiglitazone + insulin + change + diabetesMed + disch_disp_modified + adm_src_mod + adm_typ_mod + age_mod + diag1_mod + diag2_mod + diag3_mod, family=binomial, data = readmission_sub)
```

```{r, results=TRUE}
#summary(model.1)

#also takes a very long time
Anova(model.1)
```
At a significance level of 0.05 we found that 16 of the 28 variables are significant. We will create a model with just those 16 variables to compare. 

```{r, results=TRUE}
model.2 <- glm(lessThanThirty~ num_procedures + num_medications + number_emergency + number_inpatient + number_diagnoses + A1Cresult + metformin + glipizide + insulin + diabetesMed + disch_disp_modified + adm_src_mod + age_mod + diag1_mod + diag2_mod + diag3_mod, family=binomial, data = readmission_sub)

anova(model.2, model.1, test = "Chisq")
```
In running anova on the reduced model and the full model, we can see that there is no significant difference between the two different models.

```{r}
Anova(model.2)
```
Using Anova, we can determine that all of the variables selected are significant in the model. 

Now we will fit glm to the variables that LASSO selected using lambda 1se. Once again  we have factor variables in which not all of the levels were selected so we will we force all of the levels in.

```{r}
model.3 <- glm(lessThanThirty~ time_in_hospital + num_medications + number_emergency + number_inpatient + number_diagnoses + insulin + diabetesMed + disch_disp_modified + age_mod + diag1_mod + diag2_mod + diag3_mod, family=binomial, data = readmission_sub)
```

```{r}
Anova(model.3)
```

At a significance level of 0.05, the anova results indicated that all of variables used are significant except time in hospital. We can now compare this model to those that we tested for lambda min using anova.

```{r}
anova(model.2, model.3, test = "Chisq")
```
We get that for these two models, the p-value is super low meaning there is a significant difference between the two models. The key variables that differ are: num_procedures, AICresult, metformin, glipizide, adm_src_mod, and time_in_hospital. Time in hospital is the only variable used in the smaller model and it was notably found to not be statistically significant in the model. 

```{r}
#split into train, test, and validation
# Split the data:
N <- length(readmission_sub$lessThanThirty)
n1 <- floor(.6*N)
n2 <- floor(.2*N)
set.seed(10)
# Split data to three portions of .6, .2 and .2 of data size N
idx_train <- sample(N, n1)
idx_no_train <- (which(! seq(1:N) %in% idx_train))
idx_test <- sample( idx_no_train, n2)
idx_val <- which(! idx_no_train %in% idx_test)
data.train <- readmission_sub[idx_train,]
data.test <- readmission_sub[idx_test,]
data.val <- readmission_sub[idx_val,]
```

```{r}
model_min <- glm(lessThanThirty ~ num_procedures + num_medications + number_emergency + number_inpatient + number_diagnoses + A1Cresult + metformin + glipizide + insulin + diabetesMed + disch_disp_modified + adm_src_mod + age_mod + diag1_mod + diag2_mod + diag3_mod, family=binomial, data = data.train)

model_1se <- glm(lessThanThirty~ num_medications + number_emergency + number_inpatient + number_diagnoses + insulin + diabetesMed + disch_disp_modified + age_mod + diag1_mod + diag2_mod + diag3_mod, family=binomial, data = data.train)
```

```{r}
min.fitted.test <- predict(model_min, data.test, type="response") 
se.fitted.test <- predict(model_1se, data.test, type="response")
data.frame(min.fitted.test, se.fitted.test)[1:10, ]
```

```{r}
min.test.roc <- roc(data.test$lessThanThirty, min.fitted.test)
se.test.roc <- roc(data.test$lessThanThirty, se.fitted.test)
```

```{r}
plot(1-min.test.roc$specificities, min.test.roc$sensitivities,
  col="red", type="l", lwd=3,
  xlab=paste("AUC(min.test) =",
  round(pROC::auc(min.test.roc),2),
  " AUC(se.test) =",
  round(pROC::auc(se.test.roc),2)),
  ylab="Sensitivities")
  lines(1-se.test.roc$specificities, se.test.roc$sensitivities, col="blue", lwd=3)
  legend("bottomright", legend=c("Fit w lambda min variables", "Fit w lambda 1se variables"),
  lty=c(1,1), lwd=c(2,2), col=c("red", "blue"))
  title("Comparison of two models using testing data")
```
```{r}
se.fitted.val <- predict(model_1se, data.val, type="response")
pROC::auc(data.val$lessThanThirty, se.fitted.val)
```


# Analysis 
* Various appropriate statistical methods: e.g. glmnet 
* Comparisons various models
* Final model(s)

# Conclusion
* Summarize results and the final model
* Final recommendations

# Appendix
* Any thing necessary to keep but for which you don’t want them to be in the main report
* Use Appendices to display lengthy output. 


